# CorrectiveRAG-LangGraph-Gemini

This project implements a full Corrective RAG (Retrieval-Augmented Generation) pipeline using LangGraph, LangChain, Chroma, and Google Gemini.
It was built as part of an academic assignment to demonstrate multi-step RAG reasoning, iterative correction, and structured evaluation.

â¸»

ðŸŽ¯ 1. Project Overview

The system answers a user question by:
	1.	Performing an initial RAG answer
	2.	Judging whether the answer is complete, accurate, and grounded
	3.	Rewriting the question when the answer fails
	4.	Re-retrieving documents with the improved query
	5.	Generating a corrected final answer with citations

The workflow is implemented using LangGraph with clearly defined nodes, state management, and conditional edges.

â¸»

ðŸŽ“ 2. Learning Objectives

This project demonstrates:
	â€¢	How LangGraph uses state, nodes, and conditional routing
	â€¢	How to build a multi-step Corrective RAG workflow
	â€¢	How to integrate retrieval, LLM judgment, and query rewriting
	â€¢	How to generate grounded answers with proper citations
	â€¢	How to handle strict JSON evaluation for LLM judges
	â€¢	How to evaluate RAG performance based on answer completeness

â¸»

ðŸ“˜ 3. Knowledge Sources

The project retrieves information from a local vector store built from 6 official LangGraph/LangChain documentation pages, including:
	â€¢	LangGraph Overview
	â€¢	Graph API
	â€¢	Workflows & Agents
	â€¢	LangChain Retrieval
	â€¢	LangChain RAG Tutorial
	â€¢	LangChain Agents

Each chunk includes metadata:

{
  "source_url": "...",
  "section_title": "..."
}

These are used to produce clear, traceable citations.

â¸»

ðŸ§© 4. Workflow Nodes

The Corrective RAG pipeline consists of five nodes:

âœ” initial_rag

Retrieves documents and produces a draft answer.

âœ” judge

Evaluates the draft answer with a strict JSON-based scoring rubric:
	â€¢	complete?
	â€¢	grounded?
	â€¢	relevant?
	â€¢	hallucination-free?

âœ” rewrite_query

Rewrites the question based on failure reasons.

âœ” reretrieve_and_answer

Uses a stronger retriever (k=8) to answer again.

âœ” finalize

Generates the final answer with:
	â€¢	citations
	â€¢	decision log
	â€¢	rewritten queries
	â€¢	draft answer history

â¸»

ðŸ”€ 5. Graph Routing

Conditional edges determine the flow:

initial_rag â†’ judge â†’ (rewrite | finalize)
rewrite â†’ reretrieve_and_answer â†’ judge â†’ ...

The system retries once (MAX_ATTEMPTS=2), then finalizes.

â¸»

ðŸ“¦ 6. Vector Store Construction
	â€¢	Loads .html, .htm, .txt, .md files
	â€¢	Converts HTML â†’ clean text via BeautifulSoup
	â€¢	Splits into chunks using RecursiveCharacterTextSplitter
	â€¢	Saves vector store to Chroma with BCE embeddings

â¸»

ðŸ§ª 7. Running the Demo

python corrective_rag.py

If no vector store exists, the script builds one automatically.

You will be prompted:

Enter your question:

The system then runs through the full Corrective RAG workflow and prints the final structured answer.

â¸»

ðŸ§µ 8. Self-Verification Questions

The project demonstrates understanding of:
	1.	Difference between Node and Edge in LangGraph
	2.	Importance of State in workflows
	3.	How conditional routing works
	4.	Why we use MemorySaver checkpointer
	5.	Components of a standard RAG chain

â¸»

ðŸ“š 9. Tech Stack
	â€¢	Python 3.10+
	â€¢	LangGraph / LangChain
	â€¢	Google Gemini
	â€¢	ChromaDB
	â€¢	HuggingFace BCE Embeddings
	â€¢	BeautifulSoup4

â¸»

ðŸ“Œ 10. Repository Structure

CorrectiveRAG-LangGraph-Gemini/
  â”œâ”€â”€ corrective_rag.py
  â”œâ”€â”€ docs/langgraph/        # downloaded docs
  â”œâ”€â”€ vectorstore/langgraph/ # auto-generated
  â”œâ”€â”€ README.md


â¸»

ðŸ™Œ 11. Acknowledgments

This project is part of academic coursework for LangGraph and RAG systems, demonstrating structured AI evaluation and iterative correction.
